{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afd5fc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"response\":\"**랭스미스(LangSmith)는 LLM(대형 언어 모델) 개발자와 데이터 과학자들을 위해 만들어진 “모니터링·디버깅·분석” 플랫폼입니다.**\\n\\n### 1️⃣ 핵심 아이디어\\n- **LLM 애플리케이션을 눈으로 확인**할 수 있도록, “챗봇·대화형 애플리케이션”에 발생하는 모든 이벤트(프롬프트, 모델 응답, 메타데이터, 비용 등)를 기록해둡니다.\\n- 기록된 데이터를 시각화(그래프, 테이블)하면 “어디서, 왜, 얼마만큼” 잘못됐는지 한눈에 파악할 수 있습니다.\\n\\n### 2️⃣ 주요 기능\\n| 기능 | 예시 | 효과 |\\n|------|------|------|\\n| **로깅** | 발화한 프롬프트와 모델의 응답을 저장 | 나중에 같은 상황을 재현 가능 |\\n| **트레이싱** | 프롬프트 → 토큰화 → 모델 → 응답 → 후처리까지 단계별 추적 | 어느 단계에서 지연이 발생했는지 식별 |\\n| **시각화** | 응답 시간, 토큰 수, 비용 등의 KPI를 차트로 | 성능 흐름을 한 눈에 이해 |\\n| **디버깅** | 특정 사용자가 받은 ‘잘못된’ 답변을 재생성 → 원인 분석 | hallucination(허위정보) 같은 이슈를 빠르게 해결 |\\n| **A/B 테스트** | 같은 상황에서 서로 다른 프롬프트/모델를 비교 | 최적의 설정을 찾는 실험이 쉬워짐 |\\n| **메트릭 수집** | 토큰 사용량, 시간, 비용, 에러율 등 | 운영 비용 예측 및 최적화 |\\n| **통합** | LangChain·LangSmith·OpenAI·Azure·AWS 등 연동 | 기존에 사용하던 프레임워크와 바로 연결 가능 |\\n\\n### 3️⃣ 사용법 (간단 예시)\\n```python\\nfrom langsmith import Client\\nclient = Client(api_key=\\\"YOUR_API_KEY\\\")\\n\\n# 1. 프롬프트 카드를 만들어 기록\\nclient.create_run(\\n    name=\\\"음식 추천 챗봇 테스트\\\",\\n    inputs={\\\"question\\\": \\\"오늘 점심에 뭐 먹지?\\\"},\\n    outputs={\\\"answer\\\": \\\"카페라떼를 추천해요.\\\"},\\n    metadata={\\\"model\\\": \\\"gpt-4\\\", \\\"region\\\": \\\"us-west\\\"}\\n)\\n```\\n- 실행하면 **유저 인터페이스**(웹 또는 CLI)에서 바로 이 세션을 조회, 반복 재생성, 메트릭 비교가 가능해집니다.\\n\\n### 4️⃣ 왜 필요할까?\\n1. **LLM이 복잡** – 프롬프트, 토큰, 비용, 모델 버전 등 많은 변수가 동시에 동작합니다.\\n2. **문제 진단** – 해석 불가/부정확한 응답이 발생하면 어디서 잘못됐는지 알기가 어렵습니다.\\n3. **운영 비용 관리** – 토큰 사용량이 예산에 큰 영향을 미치죠.\\n\\n랭스미스를 사용하면 이 모든 과정을 **시각화·분석·디버깅**을 한 곳에서 진행해서, LLM 프로젝트를 빠르고 안정적으로 운영할 수 있습니다.\\n\\n---\\n\\n#### 한 줄 요약\\n> **랭스미스는 LLM 애플리케이션을 마치 “시스템 모니터링 도구”처럼 기록하고, 시각화하며, 문제를 해결해 주는 서비스**입니다.\\n\"}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.chdir('/Users/reejungkim/Documents/Git/working-in-progress')\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://router.huggingface.co/v1\",\n",
    "    api_key=os.environ[\"huggingface_read\"],\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"openai/gpt-oss-20b:novita\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"랭스미스에 대해 쉽게 설명해줘\"\n",
    "        }\n",
    "    ],\n",
    "    #response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b6e53cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c0964f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**랭스미스(LangSmith)는 LLM(대형 언어 모델) 개발자와 데이터 과학자들을 위해 만들어진 “모니터링·디버깅·분석” 플랫폼입니다.**\n",
      "\n",
      "### 1️⃣ 핵심 아이디어\n",
      "- **LLM 애플리케이션을 눈으로 확인**할 수 있도록, “챗봇·대화형 애플리케이션”에 발생하는 모든 이벤트(프롬프트, 모델 응답, 메타데이터, 비용 등)를 기록해둡니다.\n",
      "- 기록된 데이터를 시각화(그래프, 테이블)하면 “어디서, 왜, 얼마만큼” 잘못됐는지 한눈에 파악할 수 있습니다.\n",
      "\n",
      "### 2️⃣ 주요 기능\n",
      "| 기능 | 예시 | 효과 |\n",
      "|------|------|------|\n",
      "| **로깅** | 발화한 프롬프트와 모델의 응답을 저장 | 나중에 같은 상황을 재현 가능 |\n",
      "| **트레이싱** | 프롬프트 → 토큰화 → 모델 → 응답 → 후처리까지 단계별 추적 | 어느 단계에서 지연이 발생했는지 식별 |\n",
      "| **시각화** | 응답 시간, 토큰 수, 비용 등의 KPI를 차트로 | 성능 흐름을 한 눈에 이해 |\n",
      "| **디버깅** | 특정 사용자가 받은 ‘잘못된’ 답변을 재생성 → 원인 분석 | hallucination(허위정보) 같은 이슈를 빠르게 해결 |\n",
      "| **A/B 테스트** | 같은 상황에서 서로 다른 프롬프트/모델를 비교 | 최적의 설정을 찾는 실험이 쉬워짐 |\n",
      "| **메트릭 수집** | 토큰 사용량, 시간, 비용, 에러율 등 | 운영 비용 예측 및 최적화 |\n",
      "| **통합** | LangChain·LangSmith·OpenAI·Azure·AWS 등 연동 | 기존에 사용하던 프레임워크와 바로 연결 가능 |\n",
      "\n",
      "### 3️⃣ 사용법 (간단 예시)\n",
      "```python\n",
      "from langsmith import Client\n",
      "client = Client(api_key=\"YOUR_API_KEY\")\n",
      "\n",
      "# 1. 프롬프트 카드를 만들어 기록\n",
      "client.create_run(\n",
      "    name=\"음식 추천 챗봇 테스트\",\n",
      "    inputs={\"question\": \"오늘 점심에 뭐 먹지?\"},\n",
      "    outputs={\"answer\": \"카페라떼를 추천해요.\"},\n",
      "    metadata={\"model\": \"gpt-4\", \"region\": \"us-west\"}\n",
      ")\n",
      "```\n",
      "- 실행하면 **유저 인터페이스**(웹 또는 CLI)에서 바로 이 세션을 조회, 반복 재생성, 메트릭 비교가 가능해집니다.\n",
      "\n",
      "### 4️⃣ 왜 필요할까?\n",
      "1. **LLM이 복잡** – 프롬프트, 토큰, 비용, 모델 버전 등 많은 변수가 동시에 동작합니다.\n",
      "2. **문제 진단** – 해석 불가/부정확한 응답이 발생하면 어디서 잘못됐는지 알기가 어렵습니다.\n",
      "3. **운영 비용 관리** – 토큰 사용량이 예산에 큰 영향을 미치죠.\n",
      "\n",
      "랭스미스를 사용하면 이 모든 과정을 **시각화·분석·디버깅**을 한 곳에서 진행해서, LLM 프로젝트를 빠르고 안정적으로 운영할 수 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 한 줄 요약\n",
      "> **랭스미스는 LLM 애플리케이션을 마치 “시스템 모니터링 도구”처럼 기록하고, 시각화하며, 문제를 해결해 주는 서비스**입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def parse_response(response_str):\n",
    "    data = json.loads(response_str)\n",
    "    return data[\"response\"].replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "# 사용\n",
    "clean_text = parse_response(generated_text)\n",
    "print(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a0ae5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
