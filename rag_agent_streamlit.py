import streamlit as st
import PyPDF2
import io
import os
from typing import List
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.schema import Document
from langchain.prompts import PromptTemplate

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="RAG AI-Agent",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ì œëª©ê³¼ ì„¤ëª…
st.title("ğŸ¤– RAG AI-Agent")
st.markdown("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”!")

# ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ ì…ë ¥
with st.sidebar:
    st.header("ì„¤ì •")
    openai_api_key = st.text_input(
        "OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
        type="password",
        help="OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    )
    
    if openai_api_key:
        os.environ["OPENAI_API_KEY"] = openai_api_key

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'vectorstore' not in st.session_state:
    st.session_state.vectorstore = None
if 'qa_chain' not in st.session_state:
    st.session_state.qa_chain = None
if 'messages' not in st.session_state:
    st.session_state.messages = []

def extract_text_from_pdf(pdf_file) -> str:
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        st.error(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return ""

def create_vectorstore(text: str, api_key: str):
    """í…ìŠ¤íŠ¸ë¡œë¶€í„° ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        # í…ìŠ¤íŠ¸ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )
        
        # Document ê°ì²´ ìƒì„±
        documents = [Document(page_content=text)]
        texts = text_splitter.split_documents(documents)
        
        # ì„ë² ë”© ìƒì„±
        embeddings = OpenAIEmbeddings(openai_api_key=api_key)
        
        # FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        vectorstore = FAISS.from_documents(texts, embeddings)
        
        return vectorstore
    except Exception as e:
        st.error(f"ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None

def create_qa_chain(vectorstore, api_key: str):
    """QA ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        # LLM ì„¤ì •
        llm = ChatOpenAI(
            temperature=0,
            model_name="gpt-3.5-turbo",
            openai_api_key=api_key
        )
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
        prompt_template = """ë‹¤ìŒ ë¬¸ë§¥ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”. ë§Œì•½ ë‹µì„ ëª¨ë¥´ê² ë‹¤ë©´, ëª¨ë¥¸ë‹¤ê³  ë§í•˜ì„¸ìš”. ë‹µì„ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.

{context}

ì§ˆë¬¸: {question}
ë‹µë³€:"""

        PROMPT = PromptTemplate(
            template=prompt_template,
            input_variables=["context", "question"]
        )
        
        # RetrievalQA ì²´ì¸ ìƒì„±
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
            chain_type_kwargs={"prompt": PROMPT},
            return_source_documents=True
        )
        
        return qa_chain
    except Exception as e:
        st.error(f"QA ì²´ì¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None

# ë©”ì¸ ë ˆì´ì•„ì›ƒì„ ë‘ ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ êµ¬ì„±
col1, col2 = st.columns([1, 2])

with col1:
    st.header("ğŸ“„ PDF íŒŒì¼ ì—…ë¡œë“œ")
    
    # PDF íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader(
        "PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        type="pdf",
        help="PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )
    
    # PDF ì²˜ë¦¬
    if uploaded_file and openai_api_key:
        with st.spinner("PDFë¥¼ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = extract_text_from_pdf(uploaded_file)
            
            if text.strip():
                # ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
                vectorstore = create_vectorstore(text, openai_api_key)
                
                if vectorstore:
                    # QA ì²´ì¸ ìƒì„±
                    qa_chain = create_qa_chain(vectorstore, openai_api_key)
                    
                    if qa_chain:
                        st.session_state.vectorstore = vectorstore
                        st.session_state.qa_chain = qa_chain
                        st.success("âœ… PDF ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        
                        # ë¬¸ì„œ ì •ë³´ í‘œì‹œ
                        st.info(f"ğŸ“Š ë¬¸ì„œ ì •ë³´\n- íŒŒì¼ëª…: {uploaded_file.name}\n- í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text):,} ë¬¸ì")
            else:
                st.error("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    elif uploaded_file and not openai_api_key:
        st.warning("âš ï¸ OpenAI API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    # í˜„ì¬ ìƒíƒœ í‘œì‹œ
    if st.session_state.qa_chain:
        st.success("ğŸ¤– AI Agent ì¤€ë¹„ ì™„ë£Œ!")
    else:
        st.info("ğŸ“‹ PDFë¥¼ ì—…ë¡œë“œí•˜ê³  API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

with col2:
    st.header("ğŸ’¬ ì§ˆë¬¸ & ë‹µë³€")
    
    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    chat_container = st.container()
    
    with chat_container:
        for message in st.session_state.messages:
            if message["role"] == "user":
                st.chat_message("user").write(message["content"])
            else:
                st.chat_message("assistant").write(message["content"])
    
    # ì§ˆë¬¸ ì…ë ¥
    if st.session_state.qa_chain:
        if prompt := st.chat_input("PDF ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”..."):
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.messages.append({"role": "user", "content": prompt})
            st.chat_message("user").write(prompt)
            
            # AI ì‘ë‹µ ìƒì„±
            with st.chat_message("assistant"):
                with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    try:
                        result = st.session_state.qa_chain({"query": prompt})
                        answer = result["result"]
                        
                        st.write(answer)
                        
                        # ì†ŒìŠ¤ ë¬¸ì„œ ì •ë³´ í‘œì‹œ (ì„ íƒì‚¬í•­)
                        if "source_documents" in result and result["source_documents"]:
                            with st.expander("ğŸ“š ì°¸ê³ í•œ ë¬¸ì„œ ë¶€ë¶„"):
                                for i, doc in enumerate(result["source_documents"][:2]):
                                    st.write(f"**ì°¸ê³  {i+1}:**")
                                    st.write(doc.page_content[:300] + "...")
                        
                        # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì¶”ê°€
                        st.session_state.messages.append({"role": "assistant", "content": answer})
                        
                    except Exception as e:
                        error_msg = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                        st.error(error_msg)
                        st.session_state.messages.append({"role": "assistant", "content": error_msg})
    else:
        st.info("ë¨¼ì € PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
        
    # ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼
    if st.session_state.messages:
        if st.button("ğŸ—‘ï¸ ì±„íŒ… ê¸°ë¡ ì§€ìš°ê¸°"):
            st.session_state.messages = []
            st.rerun()

# í•˜ë‹¨ ì •ë³´
st.markdown("---")
st.markdown("""
### ì‚¬ìš© ë°©ë²•:
1. ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ **OpenAI API í‚¤**ë¥¼ ì…ë ¥í•˜ì„¸ìš”
2. **PDF íŒŒì¼**ì„ ì—…ë¡œë“œí•˜ì„¸ìš”
3. PDF ì²˜ë¦¬ê°€ ì™„ë£Œë˜ë©´ **ì§ˆë¬¸**ì„ ì…ë ¥í•˜ì„¸ìš”
4. AIê°€ PDF ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ **ë‹µë³€**ì„ ì œê³µí•©ë‹ˆë‹¤

### í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬:
```bash
pip install streamlit langchain langchain-community langchain-openai faiss-cpu PyPDF2 openai
```
""")

# ì‹¤í–‰ ëª…ë ¹ì–´ ì•ˆë‚´
st.code("streamlit run app.py", language="bash")