{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e55c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"/Users/reejungkim/Documents/Git/HuggingFace/Amazon-2024-Annual-Report.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "# for page in pages:\n",
    "#     print(page.metadata, page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "757f7fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANNUAL REPORT\n",
      "2 0 2 4 page_content='ANNUAL REPORT\n",
      "2 0 2 4' metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign 15.0 (Macintosh)', 'creationdate': '2022-02-14T21:08:55-06:00', 'author': 'T&C Composition', 'gts_pdfxconformance': 'PDF/X-1a:2001', 'gts_pdfxversion': 'PDF/X-1:2001', 'keywords': '25-4123-1_2', 'moddate': '2025-04-09T12:45:58-07:00', 'subject': 'Annual Report', 'title': 'Amazon.com, Inc.', 'trapped': '/False', 'source': '/Users/reejungkim/Documents/Git/HuggingFace/Amazon-2024-Annual-Report.pdf', 'total_pages': 91, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "for page in pages[:1]:\n",
    "    print(page.page_content, page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6be2fc7",
   "metadata": {},
   "source": [
    "# 문서 추가\n",
    "loader2 = PyPDFLoader('/Users/reejungkim/Documents/Git/HuggingFace/Amazon-2025-Proxy-Statement.pdf')\n",
    "docs2 = loader2.load()\n",
    "\n",
    "docs.extend(docs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e63beb",
   "metadata": {},
   "source": [
    "# 문서 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584cae1c",
   "metadata": {},
   "source": [
    "# Add this before your BM25 retriever creation\n",
    "print(\"Debugging docs:\")\n",
    "print(f\"Type of docs: {type(docs)}\")\n",
    "print(f\"Length of docs: {len(docs) if docs else 0}\")\n",
    "\n",
    "if docs:\n",
    "    print(f\"First doc type: {type(docs[0])}\")\n",
    "    if hasattr(docs[0], 'page_content'):\n",
    "        print(f\"First doc content: {docs[0].page_content[:200]}...\")\n",
    "    else:\n",
    "        print(f\"First doc: {docs[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "773ef5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "texts = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2539892c",
   "metadata": {},
   "source": [
    "# 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35eab0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_huggingface = HuggingFaceEmbeddings(model_name='jhgan/ko-sroberta-multitask'\n",
    "                                          , model_kwargs = {'device':'cpu'}\n",
    "                                          , encode_kwargs = {'normalize_embeddings':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4749c835",
   "metadata": {},
   "source": [
    "# 벡터 저장소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da0bf201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(texts, \n",
    "                                   model_huggingface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c0149",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vectorstore.similarity_search(\"How much of the cash used in Operating activities in the year of 2024?, k=5\")\n",
    "#answer: $ 115,877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33e85af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generally corresponds to our net sales. The increase in operating cash flow in 2024, compared to the prior year, was due to an \n",
      "increase in net income (loss), excluding non-cash expenses, and changes in working capital. Working capital at any specific \n",
      "point in time is subject to many variables, including variability in demand, inventory management and category expansion, the \n",
      "timing of cash receipts and payments, customer and vendor payment terms, and fluctuations in foreign exchange rates.\n",
      "Cash provided by (used in) investing activities corresponds with cash capital expenditures, including leasehold \n",
      "improvements, incentives received from property and equipment vendors, proceeds from asset sales, cash outlays for \n",
      "22\n",
      "with first quarter 2024. This guidance anticipates an unusually large, unfavorable impact of approximately $2.1 \n",
      "billion, or 150 basis points, from foreign exchange rates. Also, as a reminder, in first quarter 2024 the impact from \n",
      "Leap Year added approximately $1.5 billion in net sales. \n",
      "• Operating income is expected to be between $14.0 billion and $18.0 billion, compared with $15.3 billion in first \n",
      "quarter 2024.  \n",
      "• This guidance assumes, among other things, that no additional business acquisitions, restructurings, or legal \n",
      "settlements are concluded.\n",
      "30\n",
      "2023, and 2024. Expected future amortization expense of acquired finite-lived intangible assets as of December 31, 2024 is as \n",
      "follows (in millions):\n",
      " \n",
      "Year Ended December 31,\n",
      "2025 $ 994 \n",
      "2026  918 \n",
      "2027  796 \n",
      "2028  632 \n",
      "2029  615 \n",
      "Thereafter  3,484 \n",
      "$ 7,439 \n",
      "56\n",
      "During 2023, we also completed acquisition activity for immaterial aggregate cash consideration, net of cash acquired.\n",
      "2024 Acquisition Activity  \n",
      "During 2024, we completed acquisition activity for aggregate cash consideration of $780 million, net of cash acquired.\n",
      "The primary reasons for these transactions were to acquire technologies and know-how to enable Amazon to serve \n",
      "customers more effectively or to expand our customer base. \n",
      "Pro forma results of operations have not been presented because the effects of the 2024 transactions, individually and in \n",
      "the aggregate, were not material to our consolidated results of operations. Transaction-related costs were expensed as incurred \n",
      "and were not significant.\n",
      "Goodwill\n",
      "The goodwill resulting from the acquisition activity is primarily related to expected improvements in technology \n",
      "performance and functionality, as well as sales growth from future product and service offerings and new customers, together\n"
     ]
    }
   ],
   "source": [
    "for r in results:\n",
    "    print(r.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4596b79",
   "metadata": {},
   "source": [
    "# 문서 저장소 ID 확인\n",
    "vectorstore.index_to_docstore_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d0a0d",
   "metadata": {},
   "source": [
    "# 저장된 문서의 ID: Document 확인\n",
    "vectorstore.docstore._dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60de8eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever: 문서에 포함되어 있는 정보를 검색하고 생성\n",
    "\n",
    "\n",
    "# Sparse Retriever \n",
    "# TF-IDF 또는 BM25와 같은 전통적 정보검색 기법\n",
    "# 키워드 선택이 검색 품질을 좌우 (간단하고 명확한 키워드 검색에 유리)\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "bm25_retriever = BM25Retriever.from_documents(texts)\n",
    "bm25_retriever.k = 4 # set number of documents to retrieve \n",
    "\n",
    "# Dense Retriever \n",
    "# vector간의 거리 (ex.cosine similarity)\n",
    "# 키워드가 일치 하지 않아도 의미적으로 관련(뉘앙스와 문맥 일치) 문서 검색\n",
    "# 복잡한 쿼리 유리\n",
    "faiss_retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0189512f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign 15.0 (Macintosh)', 'creationdate': '2022-02-14T21:08:55-06:00', 'author': 'T&C Composition', 'gts_pdfxconformance': 'PDF/X-1a:2001', 'gts_pdfxversion': 'PDF/X-1:2001', 'keywords': '25-4123-1_2', 'moddate': '2025-04-09T12:45:58-07:00', 'subject': 'Annual Report', 'title': 'Amazon.com, Inc.', 'trapped': '/False', 'source': '/Users/reejungkim/Documents/Git/HuggingFace/Amazon-2024-Annual-Report.pdf', 'total_pages': 91, 'page': 33, 'page_label': '34'}, page_content='income tax liabilities against us. Developments in an audit, investigation, or other tax controversy could have a material effect \\non our operating results or cash flows in the period or periods for which that development occurs, as well as for prior and \\nsubsequent periods. We regularly assess the likelihood of an adverse outcome resulting from these proceedings to determine the \\nadequacy of our tax accruals. Although we believe our tax estimates are reasonable, the final outcome of audits, investigations, \\nand any other tax controversies could be materially different from our historical income tax provisions and accruals.\\nLiquidity and Capital Resources\\nCash flow information is as follows (in millions):\\n  Year Ended December 31,\\n 2023 2024\\nCash provided by (used in):\\nOperating activities $ 84,946 $ 115,877 \\nInvesting activities  (49,833)  (94,342) \\nFinancing activities  (15,879)  (11,812)'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign 15.0 (Macintosh)', 'creationdate': '2022-02-14T21:08:55-06:00', 'author': 'T&C Composition', 'gts_pdfxconformance': 'PDF/X-1a:2001', 'gts_pdfxversion': 'PDF/X-1:2001', 'keywords': '25-4123-1_2', 'moddate': '2025-04-09T12:45:58-07:00', 'subject': 'Annual Report', 'title': 'Amazon.com, Inc.', 'trapped': '/False', 'source': '/Users/reejungkim/Documents/Git/HuggingFace/Amazon-2024-Annual-Report.pdf', 'total_pages': 91, 'page': 40, 'page_label': '41'}, page_content='___________________\\n(1) For the year ended December 31, 2023 and 2024, this amount relates to equipment included in “Property and equipment \\nacquired under finance leases, net of remeasurements and modifications” of $642 million and $854 million. \\n(2) For the year ended December 31, 2023 and 2024, this amount relates to property included in “Principal repayments of \\nfinance leases” of $4,384 million and $2,043 million. \\nAll of these free cash flows measures have limitations as they omit certain components of the overall cash flow statement \\nand do not represent the residual cash flow available for discretionary expenditures. For example, these measures of free cash \\nflows do not incorporate the portion of payments representing principal reductions of debt or cash payments for business \\nacquisitions. Additionally, our mix of property and equipment acquisitions with cash or other financing options may change'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign 15.0 (Macintosh)', 'creationdate': '2022-02-14T21:08:55-06:00', 'author': 'T&C Composition', 'gts_pdfxconformance': 'PDF/X-1a:2001', 'gts_pdfxversion': 'PDF/X-1:2001', 'keywords': '25-4123-1_2', 'moddate': '2025-04-09T12:45:58-07:00', 'subject': 'Annual Report', 'title': 'Amazon.com, Inc.', 'trapped': '/False', 'source': '/Users/reejungkim/Documents/Git/HuggingFace/Amazon-2024-Annual-Report.pdf', 'total_pages': 91, 'page': 60, 'page_label': '61'}, page_content='that the carrying amount of an asset or group of assets may not be recoverable.\\nFor long-lived assets used in operations, including lease assets, impairment losses are only recorded if the asset’s carrying \\namount is not recoverable through its undiscounted, probability-weighted future cash flows. We measure the impairment loss \\nbased on the difference between the carrying amount and estimated fair value. Long-lived assets are considered held for sale \\nwhen certain criteria are met, including when management has committed to a plan to sell the asset, the asset is available for \\nsale in its immediate condition, and the sale is probable within one year of the reporting date. Assets held for sale are reported at \\nthe lower of cost or fair value less costs to sell. Assets held for sale were not significant as of December 31, 2023 and 2024.\\nAccrued Expenses and Other\\nIncluded in “Accrued expenses and other” on our consolidated balance sheets are liabilities primarily related to tax-'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign 15.0 (Macintosh)', 'creationdate': '2022-02-14T21:08:55-06:00', 'author': 'T&C Composition', 'gts_pdfxconformance': 'PDF/X-1a:2001', 'gts_pdfxversion': 'PDF/X-1:2001', 'keywords': '25-4123-1_2', 'moddate': '2025-04-09T12:45:58-07:00', 'subject': 'Annual Report', 'title': 'Amazon.com, Inc.', 'trapped': '/False', 'source': '/Users/reejungkim/Documents/Git/HuggingFace/Amazon-2024-Annual-Report.pdf', 'total_pages': 91, 'page': 55, 'page_label': '56'}, page_content='Compensation cost for all equity-classified stock awards expected to vest is measured at fair value on the date of grant \\nand recognized over the service period. The fair value of restricted stock units is determined based on the number of shares \\ngranted and the quoted price of our common stock. Such value is recognized as expense over the service period, net of \\nestimated forfeitures, using the accelerated method. Under this method, approximately 50% of the grant date fair value is \\nrecognized as expense in the first year of grant for the majority of our stock-based compensation awards. The accelerated \\nmethod also adds a higher level of sensitivity and complexity in estimating forfeitures. If an award is forfeited early in its life, \\nthe adjustment to compensation expense is much greater under an accelerated method than under a straight-line method. The \\nestimated number of stock awards that will ultimately vest requires judgment, and to the extent actual results or updated')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검색기에 쿼리를 날려 검색된 chunk 결과를 확인합니다.\n",
    "bm25_retriever.invoke(\"How much of the cash used in Operating activities in the year of 2024?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83c039ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "    \n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"<|system|>\n",
    "You are an assistant for question-answering tasks. \n",
    "Using the information contained in the context,\n",
    "give a comprehensive answer to the question.\n",
    "Respond only to the question asked, response should be concise and relevant to the question.\n",
    "Provide the number of the source document when relevant.\n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean. <|end|>\n",
    "\n",
    "<|user|>\n",
    "{question}<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9661d5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bm25_retriever: <class 'langchain_community.retrievers.bm25.BM25Retriever'>\n",
      "prompt: <class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "llm: <class 'langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint'>\n"
     ]
    }
   ],
   "source": [
    "# Make sure these are all properly defined:\n",
    "print(\"bm25_retriever:\", type(bm25_retriever))\n",
    "print(\"prompt:\", type(prompt))\n",
    "print(\"llm:\", type(llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38ce56b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Document 1: changes in estimates were not material to our consolidated results of operations for the years ended December 31, 2023 and \n",
      "2024. As of December 31, 2023 and 2024, our total self-insurance liabilities were $6.3 billion and $8.5 billion and are included \n",
      "in “Accrued expenses and other” on our consolidated balance sheets.  \n",
      "Unearned Revenue\n",
      "Unearned revenue is recorded when payments are received or due in advance of performing our service obligations and is \n",
      "recognized over the service\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.chdir('/Users/reejungkim/Documents/Git/working-in-progress')\n",
    "load_dotenv()\n",
    "\n",
    "# 사용할 모델의 저장소 ID를 설정합니다.\n",
    "repo_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,  # 모델 저장소 ID를 지정합니다.\n",
    "    max_new_tokens=256,  # 생성할 최대 토큰 길이를 설정합니다.\n",
    "    temperature=0.1,\n",
    "    huggingfacehub_api_token=os.environ[\"huggingface_read\"],  # 허깅페이스 토큰\n",
    ")\n",
    "\n",
    "# LLMChain을 초기화하고 프롬프트와 언어 모델을 전달합니다.\n",
    "# 체인(Chain) 생성\n",
    "# 단계 8: 체인(Chain) 생성\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"Format retrieved documents into a single string\"\"\"\n",
    "    return \"\\n\\n\".join([f\"Document {i+1}: {doc.page_content}\" for i, doc in enumerate(docs)])\n",
    "\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": lambda x: format_docs(bm25_retriever.invoke(x[\"question\"])),\n",
    "        \"question\": lambda x: x[\"question\"]\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "# 질문을 전달하여 LLMChain을 실행하고 결과를 출력합니다.\n",
    "\n",
    "# Simpler approach that's easier to debug\n",
    "def retrieve_and_format(question):\n",
    "    docs = bm25_retriever.invoke(question)\n",
    "    return format_docs(docs)\n",
    "\n",
    "# Test this function first\n",
    "test_context = retrieve_and_format(\"what is the revenue of Amazon in 2024\")\n",
    "print(\"Context:\", test_context[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4247ac49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] input_types={} partial_variables={} template=\"<|system|>\\nYou are an assistant for question-answering tasks. \\nUsing the information contained in the context,\\ngive a comprehensive answer to the question.\\nRespond only to the question asked, response should be concise and relevant to the question.\\nProvide the number of the source document when relevant.\\nIf you don't know the answer, just say that you don't know. \\nAnswer in Korean. <|end|>\\n\\n<|user|>\\n{question}<|end|>\\n<|assistant|>\"\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f4a43e",
   "metadata": {},
   "source": [
    "### Chroma 기반 문서 벡터화 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a43a9f",
   "metadata": {},
   "source": [
    "from langchain_chroma import Chroma  \n",
    "db = Chroma.from_documents(texts, model_huggingface )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce55e695",
   "metadata": {},
   "source": [
    "retriever = Chroma.as_retriever()\n",
    "\n",
    "question = 'who is Brad D. Smith'\n",
    "answer = retriever.invoke(question) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a69192cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7971ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
