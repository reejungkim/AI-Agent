{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acb072da",
   "metadata": {},
   "source": [
    "## Overview\n",
    "    1. Document Loader \n",
    "    2. Text splitter\n",
    "    3. Embedding model\n",
    "    4. Vector store\n",
    "    5. Retriever\n",
    "    6. Prompt template\n",
    "    7. LLM \n",
    "    8. Chain \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c1e2838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.chdir('/Users/reejungkim/Documents/Git/working-in-progress')\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfddcc7",
   "metadata": {},
   "source": [
    "### `1. Document Loader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e55c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"/Users/reejungkim/Documents/Git/HuggingFace/Amazon-2024-Annual-Report.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "### 문서 추가 as needed\n",
    "# loader2 = PyPDFLoader('/Users/reejungkim/Documents/Git/HuggingFace/Amazon-2025-Proxy-Statement.pdf')\n",
    "# docs2 = loader2.load()\n",
    "# docs.extend(docs2)\n",
    "\n",
    "# for page in pages:\n",
    "#     print(page.metadata, page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "757f7fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANNUAL REPORT\n",
      "2 0 2 4 page_content='ANNUAL REPORT\n",
      "2 0 2 4' metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign 15.0 (Macintosh)', 'creationdate': '2022-02-14T21:08:55-06:00', 'author': 'T&C Composition', 'gts_pdfxconformance': 'PDF/X-1a:2001', 'gts_pdfxversion': 'PDF/X-1:2001', 'keywords': '25-4123-1_2', 'moddate': '2025-04-09T12:45:58-07:00', 'subject': 'Annual Report', 'title': 'Amazon.com, Inc.', 'trapped': '/False', 'source': '/Users/reejungkim/Documents/Git/HuggingFace/Amazon-2024-Annual-Report.pdf', 'total_pages': 91, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "for page in pages[:1]:\n",
    "    print(page.page_content, page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e63beb",
   "metadata": {},
   "source": [
    "### `2. Text splitter`\n",
    "\n",
    "chunk_size 적절한 크기(보통 500~1000자)는 의미 있는 문맥 단위로 자르면서도 내용이 분산되지 않게 합니다. \n",
    "\n",
    "chunk_overlap은 텍스트를 쪼개는 과정에서 텍스트의 겹치는 부분을 얼마나 허용할 것인지를 결정합니다. 중요한 단어나 문장이 chunk 경계에 걸쳐 잘릴 수 있음.\n",
    "\n",
    "- `chunk_size ↓`: semantic sparsity (의미 희박)  \n",
    "- `chunk_size ↑`: semantic drift (의미 혼합, 벡터 불명확)  \n",
    "- `chunk_overlap`: 문맥 연속성과 정보 손실 방지 역할\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a51a7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)   \n",
    "texts = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2539892c",
   "metadata": {},
   "source": [
    "# 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35eab0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_huggingface = HuggingFaceEmbeddings(model_name='jhgan/ko-sroberta-multitask'\n",
    "                                          , model_kwargs = {'device':'cpu'}\n",
    "                                          , encode_kwargs = {'normalize_embeddings':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4749c835",
   "metadata": {},
   "source": [
    "# 벡터 저장소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0bf201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(texts, \n",
    "                                   model_huggingface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c0149",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vectorstore.similarity_search(\"How much of the cash used in Operating activities in the year of 2024?, k=5\")\n",
    "#answer: $ 115,877\n",
    "\n",
    "for r in results:\n",
    "    print(r.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4596b79",
   "metadata": {},
   "source": [
    "# 문서 저장소 ID 확인\n",
    "vectorstore.index_to_docstore_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d0a0d",
   "metadata": {},
   "source": [
    "# 저장된 문서의 ID: Document 확인\n",
    "vectorstore.docstore._dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60de8eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever: 문서에 포함되어 있는 정보를 검색하고 생성\n",
    "\n",
    "\n",
    "# Sparse Retriever \n",
    "# TF-IDF 또는 BM25와 같은 전통적 정보검색 기법\n",
    "# 키워드 선택이 검색 품질을 좌우 (간단하고 명확한 키워드 검색에 유리)\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "bm25_retriever = BM25Retriever.from_documents(texts)\n",
    "bm25_retriever.k = 4 # set number of documents to retrieve \n",
    "\n",
    "# Dense Retriever \n",
    "# vector간의 거리 (ex.cosine similarity)\n",
    "# 키워드가 일치 하지 않아도 의미적으로 관련(뉘앙스와 문맥 일치) 문서 검색\n",
    "# 복잡한 쿼리 유리\n",
    "faiss_retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0189512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색기에 쿼리를 날려 검색된 chunk 결과를 확인합니다.\n",
    "bm25_retriever.invoke(\"How much of the cash used in Operating activities in the year of 2024?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c039ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"<|system|>\n",
    "You are an assistant for question-answering tasks. \n",
    "Using the information contained in the context,\n",
    "give a comprehensive answer to the question.\n",
    "Respond only to the question asked, response should be concise and relevant to the question.\n",
    "Provide the number of the source document when relevant.\n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean. <|end|>\n",
    "\n",
    "<|user|>\n",
    "{question}<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fe3826",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ce56b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "\n",
    "# 사용할 모델의 저장소 ID를 설정합니다.\n",
    "repo_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,  # 모델 저장소 ID를 지정합니다.\n",
    "    max_new_tokens=256,  # 생성할 최대 토큰 길이를 설정합니다.\n",
    "    temperature=0.1,\n",
    "    huggingfacehub_api_token=os.environ[\"huggingface_read\"],  # 허깅페이스 토큰\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f3778",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LLMChain을 초기화하고 프롬프트와 언어 모델을 전달합니다.\n",
    "# 체인(Chain) 생성\n",
    "# 단계 8: 체인(Chain) 생성\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# def format_docs(docs):\n",
    "#     \"\"\"Format retrieved documents into a single string\"\"\"\n",
    "#     return \"\\n\\n\".join([f\"Document {i+1}: {doc.page_content}\" for i, doc in enumerate(docs)])\n",
    "# 후처리 함수: 여러 문서를 하나의 문자열로 묶는 역할  Format retrieved documents into a single string\n",
    "def format_docs(docs):\n",
    "    return \"\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# chain = (\n",
    "#     {\n",
    "#         \"context\": lambda x: format_docs(bm25_retriever.invoke(x[\"question\"])),\n",
    "#         \"question\": lambda x: x[\"question\"]\n",
    "#     }\n",
    "#     | prompt\n",
    "#     | llm\n",
    "#     | StrOutputParser()\n",
    "# )\n",
    "chain = (\n",
    "    {\"context\": faiss_retriever, \"question\": RunnablePassthrough()}  # 문맥을 검색하고 질문은 그대로 전달\n",
    "    | prompt  # 문맥 + 질문 → GPT로 전달될 형태로 포맷\n",
    "    | llm  # GPT가 응답 생성\n",
    "    | StrOutputParser()  # 출력된 응답을 사람이 읽을 수 있는 텍스트로 정리\n",
    ")\n",
    "\n",
    "\n",
    "# 질문을 전달하여 LLMChain을 실행하고 결과를 출력합니다.\n",
    "\n",
    "# Simpler approach that's easier to debug\n",
    "def retrieve_and_format(question):\n",
    "    docs = bm25_retriever.invoke(question)\n",
    "    return format_docs(docs)\n",
    "\n",
    "# Test this function first\n",
    "test_context = retrieve_and_format(\"what is the revenue of Amazon in 2024\")\n",
    "print(\"Context:\", test_context[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4247ac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f4a43e",
   "metadata": {},
   "source": [
    "### Chroma 기반 문서 벡터화 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a43a9f",
   "metadata": {},
   "source": [
    "from langchain_chroma import Chroma  \n",
    "db = Chroma.from_documents(texts, model_huggingface )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce55e695",
   "metadata": {},
   "source": [
    "retriever = Chroma.as_retriever()\n",
    "\n",
    "question = 'who is Brad D. Smith'\n",
    "answer = retriever.invoke(question) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69192cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7971ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
